{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#%% [markdown]\n",
        "# #  k-Nearest Neighbor (kNN) Image Classifier\n",
        "\n",
        "# Creating a kNN classifier consists of three steps:\n",
        "# - training - where we simply remember the training and test data.\n",
        "# - prediction - where we compute the distances between test and training examples, rank them in the ascending order, and pick the label held by k closest training images. \n",
        "# - tuning & accuracy check - where we use cross validation to tune our hyperparameter k and check the accuracy of our model.\n",
        "#\n",
        "# In building this classifer, we will follow the above outlined steps in the given order.\n",
        "#%%\n",
        "# Run some setup code for this notebook.\n",
        "from __future__ import print_function\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from data_utils import load_CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
        "# rather than in a new window (from cs231n source code)\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython (from cs231n source code).\n",
        "get_ipython().run_line_magic('load_ext', 'autoreload')\n",
        "get_ipython().run_line_magic('autoreload', '2')\n",
        "\n",
        "\n",
        "#%%\n",
        "# Load the raw CIFAR-10 data.\n",
        "cifar10_dir = 'Datasets/cifar-10-batches-py'\n",
        "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "#%%\n",
        "# Subsample the data for more efficient code execution\n",
        "num_training = 5000\n",
        "mask = list(range(num_training))\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "num_test = 500\n",
        "mask = list(range(num_test))\n",
        "X_test = X_test[mask]\n",
        "y_test = y_test[mask]\n",
        "\n",
        "\n",
        "#%%\n",
        "# Reshape the image data into rows\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "\n",
        "#%%\n",
        "from cs231n.classifiers import KNearestNeighbor\n",
        "\n",
        "#%% [markdown]\n",
        "# ###Training.\n",
        "\n",
        "# the Classifier simply remembers the data and does no further processing \n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "\n",
        "#%% [markdown]\n",
        "# ### Cross-validation\n",
        "# \n",
        "# In order to find the best-performing value for k, we use cross validation.\n",
        "\n",
        "#%%\n",
        "num_folds = 5\n",
        "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
        "\n",
        "# Split the data into folds\n",
        "X_train_folds = np.array_split(X_train, num_folds)\n",
        "y_train_folds = np.array_split(y_train, num_folds)\n",
        "\n",
        "# A dictionary holding the accuracies for different values of k that we find\n",
        "# when running cross-validation. After running cross-validation,\n",
        "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
        "# accuracy values that we found when using that value of k.\n",
        "k_to_accuracies = {}\n",
        "\n",
        "for k in k_choices:\n",
        "    k_to_accuracies[k] = []\n",
        "    \n",
        "    for i in range(num_folds):\n",
        "\n",
        "        # This picks a validation fold and concatenates all the other folds for \n",
        "        # training. \n",
        "        X_val_cross = X_train_folds[i]\n",
        "        y_val_cross = y_train_folds[i]\n",
        "        X_train_cross = np.concatenate(X_train_folds[:i] + X_train_folds[i+1:])\n",
        "        y_train_cross = np.concatenate(y_train_folds[:i] + y_train_folds[i+1:])\n",
        "\n",
        "        classifier.train(X_train_cross, y_train_cross)\n",
        "        y_pred_cross = classifier.predict(X_val_cross, k=k)\n",
        "        num_correct_cross = np.sum(y_pred_cross == y_val_cross)\n",
        "        accuracy_cross = float(num_correct_cross) / len(y_val_cross)\n",
        "        \n",
        "        \n",
        "        k_to_accuracies[k].append(accuracy_cross)\n",
        "\n",
        "# Print out the computed accuracies\n",
        "for k in sorted(k_to_accuracies):\n",
        "    for accuracy in k_to_accuracies[k]:\n",
        "        print('k = %d, accuracy = %f' % (k, accuracy))\n",
        "\n",
        "#%%\n",
        "# plot the raw observations\n",
        "for k in k_choices:\n",
        "    accuracies = k_to_accuracies[k]\n",
        "    plt.scatter([k] * len(accuracies), accuracies)\n",
        "\n",
        "# plot the trend line with error bars that correspond to standard deviation\n",
        "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
        "plt.title('Cross-validation on k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Cross-validation accuracy')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#%%\n",
        "# Based on the cross validation above, we can see that the model achieves highest\n",
        "# model accuracy for k = 10. Therefore, we pick this value and proceed with model\n",
        "# prediction.\n",
        "best_k = 10\n",
        "\n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "y_test_pred = classifier.predict(X_test, k=best_k)\n",
        "\n",
        "# Compute and display the accuracy\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#%%\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
